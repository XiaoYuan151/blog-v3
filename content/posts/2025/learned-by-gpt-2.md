---
title: 通过微调 GPT-2 学习自回归模型的原理
description: 你可以教我如何变得真实吗？
date: 2025-08-30 12:10:43
updated: 2025-10-01 12:24:38
categories: [人工智能]
tags: [人工智能, 大语言模型]
---

# 前言

自从 `2022年11月30日` OpenAI 首次发布一个真正意义上的可对话的大语言模型以来，本身一项小众的技术逐渐走进千家万户，这就让很多人零门槛用上了大语言模型，但是却也带来了一些人的困惑：`为什么连个数单词都不会`，`为什么单词里有几个字母都不知道`

其实这些都是自回归类型的大语言模型本身问题，本篇文章将从了解自回归模型入手，带你理解这几个问题出现的原因。

**本文基于作者的理解和实践，可能与现实情况存在出入。**

**本文无 AI 成分，请勿用于 AI 训练！**

**如有错误，敬请指出。**

# 开始

## 基础知识

你需要理解的内容：

- `Transformers` 是一个常用的大语言模型架构，可以处理自然语言输入。相关原理可见：[How do Transformers work?](//huggingface.co/learn/llm-course/chapter1/4)
- 在大语言模型中，`Token` 指的是每一个由机器自动切分的词语，例如 `apple` 是一个 `Token`，`straw berry` 是两个 `Token`（此处假设计算机不知道 `strawberry` 是一整个单词，而是拆开理解每个部分，实际情况中会随着机器学习的进步使得 `Token` 切分也一同进步）
- 任何大语言模型都无法脱离一些特殊 `Token`，虽然各家模型都不一样，但是本质上都是 `起始标记` `结束标记` `搜索标记` 等。
- 大语言模型无法自主控制任何东西，只能由人类预设好程序使其能够控制外部程序，通常都在输出特殊 `Token` 时触发。
- 根据 `不重复造轮子` 原则，现阶段模型训练不吃任何基础（就算你一点数学都没学过，也能完成模型训练），只看算力水平。
- 当前几乎所有大语言模型都在进行 `猜词`，训练模型数据量越大，猜的就越准（也就越像人）
- 任何模型都需要一个 `随机数` 作为决定下一次输出的关键因素，这也造成了同一个问题每一次回答都不一样，当然也可以将 `温度` 设为 `100%` 以确保每次输出结果都一致。
- 任何自回归模型**永远无法取代人类**，请不要担心。

## 进行微调

微调 GPT-2 难点在于自回归部分，本质上 GPT-2 不能进行自回归，只能告诉你每个输出的结果让你自行选择，这也是本文为何选择 GPT-2 进行微调的原因。

本文会完成自回归部分，特殊 `Token` 部分，让 GPT-2 也能拥有最新模型的特性。

### 自回归部分
